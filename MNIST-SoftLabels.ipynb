{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(12)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(12)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np \n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    (train_xf, train_yf), (test_xf, test_yf) = mnist.load_data()\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    \n",
    "    removed = [] \n",
    "    \n",
    "    for i in range(10):\n",
    "        train_idx = np.where(train_yf == i)[0][0]\n",
    "        train_x.append(train_xf[train_idx])\n",
    "        train_y.append(train_yf[train_idx])\n",
    "        removed.append(train_idx)\n",
    "        \n",
    "        test_idx = np.where(test_yf == i)[0][0:100]\n",
    "        test_x.extend(test_xf[test_idx])\n",
    "        test_y.extend(test_yf[test_idx])\n",
    "            \n",
    "    train_x = np.array(train_x, dtype='float32').reshape((len(train_x),28,28,1))\n",
    "    test_x = np.array(test_x, dtype='float32').reshape((len(test_x),28,28,1))\n",
    "    train_x = train_x/255.0\n",
    "    test_x = test_x/255.0\n",
    "    \n",
    "    train_y = to_categorical(train_y)\n",
    "    test_y = to_categorical(test_y)    \n",
    "    \n",
    "    unlabeled = np.delete(train_xf, removed, axis=0)\n",
    "    unlabeled = unlabeled.reshape((unlabeled.shape[0],28,28,1))\n",
    "    unlabeled = unlabeled/255.0\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, unlabeled\n",
    "   \n",
    "    \n",
    "def get_model(): \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(24,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(units=50, activation='relu'))\n",
    "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n",
      "(10, 10)\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, unlabeled = get_data()\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8913 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2711 - accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2351 - accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9973 - accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2448 - accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.6479 - accuracy: 0.3860\n",
      "Baseline Loss: 2.6478679180145264\n",
      "Baseline Accuracy: 0.38600000739097595\n"
     ]
    }
   ],
   "source": [
    "model_baseline = get_model()\n",
    "\n",
    "base_log = model_baseline.fit(train_x, train_y,\n",
    "                  batch_size = 1,\n",
    "                  epochs = 10, \n",
    "                  shuffle=True,                \n",
    "                  verbose = 1)\n",
    "\n",
    "base_score = model_baseline.evaluate(test_x,test_y)\n",
    "print(\"Baseline Loss: \" + str(base_score[0]))\n",
    "print(\"Baseline Accuracy: \" + str(base_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34599998593330383, 0.33000001311302185, 0.25699999928474426, 0.3840000033378601, 0.42800000309944153, 0.3190000057220459, 0.3709999918937683, 0.34299999475479126, 0.27399998903274536, 0.4189999997615814]\n",
      "Average accuracy over 10 runs: 0.3470999985933304 Std: 0.05598501918894285\n"
     ]
    }
   ],
   "source": [
    "stats = [] \n",
    "\n",
    "for i in range(10):\n",
    "    model = get_model()\n",
    "    model.fit(train_x, train_y,\n",
    "              batch_size = 1,\n",
    "              epochs = 10, \n",
    "              shuffle=True,                \n",
    "              verbose = 0)\n",
    "    stats.append(model.evaluate(test_x,test_y, verbose=0)[1])\n",
    "\n",
    "print(stats)\n",
    "print(\"Average accuracy over 10 runs: \" + str(mean(stats)) + \" Std: \" + str(stdev(stats))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_semi_supervised(model, train_x, train_y, unlabeled, n_epochs, warmup, n_labeled, n_soft, verbose=1):\n",
    "    n_batches = int(train_x.shape[0]/n_labeled)\n",
    "\n",
    "    for i in range(n_epochs): \n",
    "        idx_labeled = np.random.permutation(train_x.shape[0])\n",
    "        idx_unlabeled = np.random.permutation(unlabeled.shape[0])\n",
    "        loss_epoch = []\n",
    "        \n",
    "        soft_x = []\n",
    "        soft_y = []\n",
    "        if i >= warmup:\n",
    "            idx_soft = idx_unlabeled[0:n_batches*n_soft]\n",
    "            soft_x = unlabeled[idx_soft]\n",
    "            soft_y = model.predict(soft_x)\n",
    "            \n",
    "        u_start = 0\n",
    "        for j in range(0, train_x.shape[0], n_labeled):\n",
    "            idx_lbatch = idx_labeled[j:j+n_labeled]\n",
    "            batch_x = train_x[idx_lbatch]\n",
    "            batch_y = train_y[idx_lbatch]\n",
    "            \n",
    "            \n",
    "            if i >= warmup:\n",
    "                batch_x = np.vstack((batch_x,soft_x[u_start:u_start+n_soft]))\n",
    "                batch_y = np.vstack((batch_y,soft_y[u_start:u_start+n_soft]))\n",
    "            \n",
    "                u_start+=n_soft\n",
    "                \n",
    "            \n",
    "            loss_epoch.append(model.train_on_batch(batch_x,batch_y)[0])\n",
    "        \n",
    "        if verbose:\n",
    "            if i >= warmup:\n",
    "                print(\"Epoch \" + str(i+1) + \" loss = \" + str (mean(loss_epoch)) + \" num soft labels = \" + str(soft_y.shape[0]))\n",
    "            else:\n",
    "                print(\"Epoch \" + str(i+1) + \" loss = \" + str (mean(loss_epoch)))\n",
    "    \n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 3.49590425491333\n",
      "Epoch 2 loss = 2.0847004890441894\n",
      "Epoch 3 loss = 2.0914288997650146\n",
      "Epoch 4 loss = 1.6732263803482055\n",
      "Epoch 5 loss = 0.8123651742935181\n",
      "Epoch 6 loss = 1.0073785543441773 num soft labels = 15\n",
      "Epoch 7 loss = 0.9152100086212158 num soft labels = 15\n",
      "Epoch 8 loss = 0.7395816922187806 num soft labels = 15\n",
      "Epoch 9 loss = 0.5468575894832611 num soft labels = 15\n",
      "Epoch 10 loss = 0.5464791834354401 num soft labels = 15\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.3923 - accuracy: 0.4020\n",
      "Loss: 2.392266035079956\n",
      "Accuracy: 0.4020000100135803\n"
     ]
    }
   ],
   "source": [
    "model_ratio = get_model()\n",
    "model_ratio = train_semi_supervised(model_ratio, train_x, train_y, unlabeled, n_epochs=10, warmup=5, n_labeled=2, n_soft=3)\n",
    "\n",
    "score = model_ratio.evaluate(test_x,test_y)\n",
    "print(\"Loss: \" + str(score[0]))\n",
    "print(\"Accuracy: \" + str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42100000381469727, 0.42100000381469727, 0.3179999887943268, 0.35100001096725464, 0.367000013589859, 0.32899999618530273, 0.4099999964237213, 0.3889999985694885, 0.3790000081062317, 0.3190000057220459]\n",
      "Average accuracy over 10 runs: 0.3704000025987625 Std: 0.04027461422549332\n"
     ]
    }
   ],
   "source": [
    "stats = [] \n",
    "\n",
    "for i in range(10):\n",
    "    model = get_model()\n",
    "    model = train_semi_supervised(model, train_x, train_y, unlabeled, n_epochs=10, warmup=5, n_labeled=2, n_soft=3, verbose=0)\n",
    "    stats.append(model.evaluate(test_x,test_y, verbose=0)[1])\n",
    "\n",
    "print(stats)\n",
    "print(\"Average accuracy over 10 runs: \" + str(mean(stats)) + \" Std: \" + str(stdev(stats))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_semi_supervised_with_threshold(model, train_x, train_y, unlabeled, n_epochs, warmup, n_labeled, max_soft, thresh = 0.7, verbose = 1):\n",
    "    n_batches = int(train_x.shape[0]/n_labeled) \n",
    "         \n",
    "    for i in range(n_epochs): \n",
    "        idx_labeled = np.random.permutation(train_x.shape[0])\n",
    "        idx_unlabeled = np.random.permutation(unlabeled.shape[0])\n",
    "        loss_epoch = []\n",
    "        \n",
    "        soft_x = []\n",
    "        soft_y = []\n",
    "        n_soft = 0\n",
    "        if i >= warmup:\n",
    "            idx_soft = idx_unlabeled[0:n_batches*max_soft]\n",
    "            soft_x = unlabeled[idx_soft]\n",
    "            soft_y = model.predict(soft_x)\n",
    "\n",
    "            for j in range(soft_y.shape[0]-1,0,-1):\n",
    "                max_idx = np.argmax(soft_y[j])\n",
    "                if soft_y[j][max_idx] < thresh: \n",
    "                    soft_x = np.delete(soft_x, j, axis=0)\n",
    "                    soft_y = np.delete(soft_y, j, axis=0)\n",
    "                    \n",
    "            n_soft = int(soft_y.shape[0]/n_batches)                \n",
    "                    \n",
    "            \n",
    "        u_start = 0\n",
    "        for j in range(0, train_x.shape[0], n_labeled):\n",
    "            idx_lbatch = idx_labeled[j:j+n_labeled]\n",
    "            batch_x = train_x[idx_lbatch]\n",
    "            batch_y = train_y[idx_lbatch]\n",
    "            \n",
    "            \n",
    "            if i >= warmup and soft_y.shape[0] > 0:\n",
    "                batch_x = np.vstack((batch_x,soft_x[u_start:u_start+n_soft]))\n",
    "                batch_y = np.vstack((batch_y,soft_y[u_start:u_start+n_soft]))\n",
    "                u_start+=n_soft\n",
    "                \n",
    "            \n",
    "            loss_epoch.append(model.train_on_batch(batch_x,batch_y)[0])\n",
    "        \n",
    "        if verbose:\n",
    "            if i >= warmup:\n",
    "                print(\"Epoch \" + str(i+1) + \" loss = \" + str (mean(loss_epoch)) + \" num soft labels = \" + str(soft_y.shape[0]))\n",
    "            else:\n",
    "                print(\"Epoch \" + str(i+1) + \" loss = \" + str (mean(loss_epoch)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 3.0067036628723143\n",
      "Epoch 2 loss = 2.135382604598999\n",
      "Epoch 3 loss = 1.8965614080429076\n",
      "Epoch 4 loss = 1.245452618598938\n",
      "Epoch 5 loss = 0.42315216809511186\n",
      "Epoch 6 loss = 0.2195932887494564 num soft labels = 6\n",
      "Epoch 7 loss = 0.284084795974195 num soft labels = 9\n",
      "Epoch 8 loss = 0.38459505438804625 num soft labels = 16\n",
      "Epoch 9 loss = 0.17222611010074615 num soft labels = 11\n",
      "Epoch 10 loss = 0.29417295157909396 num soft labels = 18\n",
      "Epoch 11 loss = 0.31696334332227705 num soft labels = 19\n",
      "Epoch 12 loss = 0.22187330648303033 num soft labels = 14\n",
      "Epoch 13 loss = 0.23231619000434875 num soft labels = 18\n",
      "Epoch 14 loss = 0.2951685391366482 num soft labels = 21\n",
      "Epoch 15 loss = 0.2730750322341919 num soft labels = 18\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.9644 - accuracy: 0.3910\n"
     ]
    }
   ],
   "source": [
    "model_thresh = get_model()\n",
    "model_thresh = train_semi_supervised_with_threshold(model_thresh, train_x, train_y, unlabeled, \n",
    "                                                    n_epochs=15, warmup=5, n_labeled=2, max_soft=5)\n",
    "\n",
    "thresh_score = model_thresh.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28700000047683716, 0.39100000262260437, 0.21899999678134918, 0.22200000286102295, 0.42399999499320984, 0.3490000069141388, 0.31200000643730164, 0.4449999928474426, 0.296999990940094, 0.3199999928474426]\n",
      "Average accuracy over 10 runs: 0.3265999987721443 Std: 0.07700966640454228\n"
     ]
    }
   ],
   "source": [
    "stats = [] \n",
    "\n",
    "for i in range(10):\n",
    "    model = get_model()\n",
    "    model = train_semi_supervised_with_threshold(model, train_x, train_y, unlabeled, \n",
    "                                                 n_epochs=15, warmup=5, n_labeled=2, max_soft=5, thresh = 0.7, verbose=0)\n",
    "    stats.append(model.evaluate(test_x,test_y, verbose=0)[1])\n",
    "\n",
    "print(stats)\n",
    "print(\"Average accuracy over 10 runs: \" + str(mean(stats)) + \" Std: \" + str(stdev(stats))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, image):\n",
    "    scores = model.predict(image)\n",
    "    return np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = test_x[246]\n",
    "pred_base = get_prediction(baseline_model,np.expand_dims(image,axis=0))\n",
    "pred_ratio = get_prediction(model_ratio,np.expand_dims(image,axis=0))\n",
    "pred_thresh = get_prediction(model_thresh,np.expand_dims(image,axis=0))\n",
    "\n",
    "plt.imshow(image)\n",
    "print(str(pred_base) + \" \" + str(pred_ratio) + \" \" + str(pred_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
